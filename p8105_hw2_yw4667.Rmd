---
title: "Untitled"
output: github_document
date: "2025-09-24"
---

```{r set up}
library(tidyverse)
library(readxl)
options(tibble.print_min = 5)
```

# Problem 1
## 1.1 pols_month
```{r}
pols_month = 
  read_csv(
    "./fivethirtyeight_datasets/pols-month.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month","day"), sep = "-")|>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    month = 
      case_match(
        month, 
        01 ~ "Jan", 
        02 ~ "Feb",
        03 ~ "Mar",
        04 ~ "Apr",
        05 ~ "May",
        06 ~ "Jun",
        07 ~ "Jul",
        08 ~ "Aug",
        09 ~ "Sep",
        10 ~ "Oct",
        11 ~ "Nov",
        12 ~ "Dec"),
    month = as.factor(month),
    year = as.factor(year)) |>
  relocate(prez_dem,prez_gop) |>
  pivot_longer(
    prez_dem:prez_gop,
    names_to = "president", 
    values_to = "prez_dem_or_prez_gop",
    names_prefix = "prez_" ) |>
  filter(prez_dem_or_prez_gop == 1)|>
  select(-day,-prez_dem_or_prez_gop)|>
  select(year,month,everything())
print(pols_month)
```

## 1.2 snp
```{r}
snp = 
  read_csv(
    "./fivethirtyeight_datasets/snp.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(date, into = c( "month","day","year"), sep = "/")|>
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = 
      case_match(
        month, 
        1 ~ "Jan", 
        2 ~ "Feb",
        3 ~ "Mar",
        4 ~ "Apr",
        5 ~ "May",
        6 ~ "Jun",
        7 ~ "Jul",
        8 ~ "Aug",
        9 ~ "Sep",
        10 ~ "Oct",
        11 ~ "Nov",
        12 ~ "Dec")) |>
  mutate(
  year = case_when(
    year >= 50 ~ paste0("19", year), 
    year < 50 ~ paste0("20", year)),
    month = as.factor(month),
    year = as.factor(year)
)|>
  select(-day)|>
  select(year,month,everything())
print(snp)
```
## 1.3 unemployment
```{r}
unemployment = 
  read_csv(
    "./fivethirtyeight_datasets/unemployment.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names()|>
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment") |>
   mutate(
    year = as.integer(year),
    month = 
      case_match(
        month, 
        "jan" ~ "Jan", 
        "feb" ~ "Feb",
        "mar" ~ "Mar",
        "apr" ~ "Apr",
        "may" ~ "May",
        "jun" ~ "Jun",
        "jul" ~ "Jul",
        "aug" ~ "Aug",
        "sep" ~ "Sep",
        "oct" ~ "Oct",
        "nov" ~ "Nov",
        "dec" ~ "Dec"),
    month = as.factor(month),
    year = as.factor(year)) |>
    select(year,month,everything())
print(unemployment)
```
## 1.4 dataset1 merged
```{r}
dataset1_merged = 
  full_join(pols_month, snp, by = c("year","month")) |>
  full_join(unemployment, by = c("year","month"))
print(dataset1_merged)
```

## 1.5 descriptions

The first dataset`pols_month`contained information about the political composition of government by month, including the number of Republican and Democratic governors, senators, representatives, and the political party of the sitting president. The data was restructured to create a single variable indicating whether the president was Democratic or Republican for each time period.

The second dataset`snp`contained stock market index closing values by date. The dates were reformatted and years were converted from 2-digit to 4-digit format (with years â‰¥50 treated as 1950s-1990s and years <50 as 2000s-2040s).

The third dataset`unemployment`contained monthly unemployment percentages by year in wide format, which was pivoted to long format with sxeparate month and unemployment rate columns.

The final dataset`dataset1_merged`combined all three sources, using full joins on year and month variables. It spans multiple decades and includes key variables such as `year`, `month`, `president` (party affiliation), numbers of Republican and Democratic officials in various government positions (`gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`), closing values (`close`), and unemployment rates (`unemployment`), which provided a comprehensive view of political composition, economic indicators, and market performance over time, allowing for analysis of relationships between political control, stock market performance, and unemployment rates.


# Problem 2
## 2.1 Mr. Trash Wheel sheet
```{r}
Mr_Trash_wheel = 
  read_excel(
    "./trashwheel_datasets/202509 Trash Wheel Collection Data.xlsx",
    sheet = 1,
    na = c("NA", "", "."),
    skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(sports_balls_rounded = round(sports_balls))|>
  select(-sports_balls,-x15,-x16) |>
  mutate(sports_balls_rounded = as.integer(sports_balls_rounded)) |>
  mutate(year = as.double(year))
print(Mr_Trash_wheel)
```

## 2.2 Professor Trash Wheel sheet
```{r}
Prof_Trash_wheel = 
  read_excel(
    "./trashwheel_datasets/202509 Trash Wheel Collection Data.xlsx",
    sheet = 2,
    na = c("NA", "", "."),
    skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster)
print(Prof_Trash_wheel)
```

## 2.3 Gwynnda sheet
```{r}
Gwynnda = 
  read_excel(
  "./trashwheel_datasets/202509 Trash Wheel Collection Data.xlsx",
  sheet = 4,
  range = cell_limits(c(2, 1), c(266, 12)),
  na = c("NA", "", "."))  |>
  janitor::clean_names() |>
  drop_na(dumpster)
print(Gwynnda)
```

## 2.4 dataset2 merged
```{r}
dataset2_merged = 
  full_join(Mr_Trash_wheel, Prof_Trash_wheel, by = c("dumpster","month","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","plastic_bags","wrappers","homes_powered")) |>
  full_join(Gwynnda, by = c("dumpster","month","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","plastic_bags","wrappers","homes_powered"))
print(dataset2_merged)
```

## 2.5 descriptions
The resulting dataset contains information from all three Trash Wheel collectors (`Mr_Trash_wheel`, `Prof_Trash_wheel`, and `Gwynnda`) with 802 observations and 15 variables. Every observation has its identical variables `dumpster`,`month`,`year`,`date`,`weight_tons`,`volume_cubic_yards`,`plastic_bottles`,`polystyrene`,`cigarette_butts`,`plastic_bags`,`wrappers`,`homes_powered`,meanwhile some of the observations has the `glass_bottles`,`sports_balls`.

### 2.5.1 total weight tons (Professor Trash Wheel)
```{r}
Prof_Trash_wheel |>
  drop_na(weight_tons) |>
  summarize(total_weight_tons = sum(weight_tons))
print(Prof_Trash_wheel)
```

### 2.5.2 total cigarette butts (Gwynnda June 2022)
```{r}
Gwynnda|>
  filter(year == "2022", month == "June") |>
  summarize(total_cigarette_butts = sum(cigarette_butts))
print(Gwynnda)
```

# Problem 3
## 3.1 zip codes dataset
```{r}
zip_codes = 
  read_csv(
    "./zillow_data/Zip Codes.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(file_date, into = c("month","day","year"), sep = "/") |>
  select(-state_fips,-county_code) |>
  mutate(zip_code = as.character(zip_code)) |>
  arrange(zip_code, year,month,day) |>
  mutate(year = if_else(year == "07", "2007", year)) |>
  select(county,zip_code,year,month,day,everything())
print(zip_codes)
```

## 3.2 zori dataset
```{r}
zori = 
  read_csv(
    "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  rename(zip_code = region_name,county = county_name) |>
  mutate(zip_code = as.character(zip_code))
print(zori)
```

## 3.3 zori rent price dataset
```{r}
zori_rent_price =
  zori |>
  mutate(county = str_remove(county, " County")) |>
  pivot_longer(
    cols = starts_with("x"),
    names_to = "date", 
    values_to = "rent_price",
    names_prefix = "x"
  ) |>
  mutate(zip_code = as.character(zip_code)) |>
  filter(!is.na(rent_price)) |>
  arrange(zip_code, date) |>
  separate(date, into = c("year","month","day"), sep = "_") |>
  select(county,zip_code,year,month,day,everything())
print(zori_rent_price)
```

## 3.4 dataset3 merged
```{r}
dataset3_merged = 
  full_join(zip_codes,zori_rent_price,by = c("zip_code","county","year","month","day"))
print(dataset3_merged)
```

## 3.5 descriptions
The resulting dataset contains information from two zillow datasets (`zip_codes`and`zori`) with 10772 observations and 15 variables. Every observation has its identical variables `county`,`zip_code`,`month`,`year`,`day`, and some other variables such as`county_fips`,`neighborhood`,`region_id`,`size_rank`etc.

### 3.5.1 unique zip codes
```{r}
unique_zips_merged =
  dataset3_merged |>
  distinct(zip_code) |>
  nrow()
print(unique_zips_merged)
```
### 3.5.2 unique neighborhoods
```{r}
unique_neighborhoods_merged =
  dataset3_merged |>
  drop_na(neighborhood) |>
  distinct(neighborhood) |>
  nrow()
print(unique_neighborhoods_merged)
```

### 3.5.3 unique zip codes in `zip_codes`
```{r}
zip_codes_only =
  zip_codes |>
  distinct(zip_code) |>
  anti_join(zori |> distinct(zip_code), by = "zip_code")
print(zip_codes_only)
```

### 3.5.4 possible explanation about the unique zipcodes
These ZIP codes in Manhattan, New York, are excluded from Zillow's database primarily because they are not typical residential areas and lack sufficient real estate transaction data.

For example, `10008` is the location of the New York Stock Exchange, a purely commercial and financial district with no residential properties. 

Another example, `10020`, serves the Rockefeller Center, which is a complex of offices, studios, and retail spaces, with almost no ordinary homes available for valuation.

These areas either have no housing stock, or the properties are too unique and rarely traded, making it impossible for Zillow's automated valuation model to generate a meaningful "Zestimate".

### 3.5.5 top 10 price drops
```{r}
top10_drops =
  zori_rent_price |>
  filter(year %in% c("2020","2021"), month == "01", day == "31") |> 
  select(zip_code, year, rent_price) |>
  pivot_wider(
    names_from = year, 
    values_from = rent_price,
    names_prefix = "price_of_") |>
  mutate(drop = price_of_2020 - price_of_2021) |>
  arrange(desc(drop)) |>
  drop_na(drop) |>
  head(n = 10)
print(top10_drops)
```