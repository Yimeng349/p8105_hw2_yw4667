Untitled
================
2025-09-24

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
options(tibble.print_min = 5)
```

# Problem 1

## 1.1 pols_month

``` r
pols_month = 
  read_csv(
    "./fivethirtyeight_datasets/pols-month.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month","day"), sep = "-")|>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    month = 
      case_match(
        month, 
        01 ~ "Jan", 
        02 ~ "Feb",
        03 ~ "Mar",
        04 ~ "Apr",
        05 ~ "May",
        06 ~ "Jun",
        07 ~ "Jul",
        08 ~ "Aug",
        09 ~ "Sep",
        10 ~ "Oct",
        11 ~ "Nov",
        12 ~ "Dec"),
    month = as.factor(month),
    year = as.factor(year)) |>
  relocate(prez_dem,prez_gop) |>
  pivot_longer(
    prez_dem:prez_gop,
    names_to = "president", 
    values_to = "prez_dem_or_prez_gop",
    names_prefix = "prez_" ) |>
  filter(prez_dem_or_prez_gop == 1)|>
  select(-day,-prez_dem_or_prez_gop)|>
  select(year,month,everything())
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(pols_month)
```

    ## # A tibble: 817 × 9
    ##   year  month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##   <fct> <fct>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ## 1 1947  Jan        23      51     253      23      45     198 dem      
    ## 2 1947  Feb        23      51     253      23      45     198 dem      
    ## 3 1947  Mar        23      51     253      23      45     198 dem      
    ## 4 1947  Apr        23      51     253      23      45     198 dem      
    ## 5 1947  May        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

## 1.2 snp

``` r
snp = 
  read_csv(
    "./fivethirtyeight_datasets/snp.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(date, into = c( "month","day","year"), sep = "/")|>
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = 
      case_match(
        month, 
        1 ~ "Jan", 
        2 ~ "Feb",
        3 ~ "Mar",
        4 ~ "Apr",
        5 ~ "May",
        6 ~ "Jun",
        7 ~ "Jul",
        8 ~ "Aug",
        9 ~ "Sep",
        10 ~ "Oct",
        11 ~ "Nov",
        12 ~ "Dec")) |>
  mutate(
  year = case_when(
    year >= 50 ~ paste0("19", year), 
    year < 50 ~ paste0("20", year)),
    month = as.factor(month),
    year = as.factor(year)
)|>
  select(-day)|>
  select(year,month,everything())
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(snp)
```

    ## # A tibble: 787 × 3
    ##   year  month close
    ##   <fct> <fct> <dbl>
    ## 1 2015  Jul   2080.
    ## 2 2015  Jun   2063.
    ## 3 2015  May   2107.
    ## 4 2015  Apr   2086.
    ## 5 2015  Mar   2068.
    ## # ℹ 782 more rows

## 1.3 unemployment

``` r
unemployment = 
  read_csv(
    "./fivethirtyeight_datasets/unemployment.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names()|>
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment") |>
   mutate(
    year = as.integer(year),
    month = 
      case_match(
        month, 
        "jan" ~ "Jan", 
        "feb" ~ "Feb",
        "mar" ~ "Mar",
        "apr" ~ "Apr",
        "may" ~ "May",
        "jun" ~ "Jun",
        "jul" ~ "Jul",
        "aug" ~ "Aug",
        "sep" ~ "Sep",
        "oct" ~ "Oct",
        "nov" ~ "Nov",
        "dec" ~ "Dec"),
    month = as.factor(month),
    year = as.factor(year)) |>
    select(year,month,everything())
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(unemployment)
```

    ## # A tibble: 816 × 3
    ##   year  month unemployment
    ##   <fct> <fct>        <dbl>
    ## 1 1948  Jan            3.4
    ## 2 1948  Feb            3.8
    ## 3 1948  Mar            4  
    ## 4 1948  Apr            3.9
    ## 5 1948  May            3.5
    ## # ℹ 811 more rows

## 1.4 dataset1 merged

``` r
dataset1_merged = 
  full_join(pols_month, snp, by = c("year","month")) |>
  full_join(unemployment, by = c("year","month"))
print(dataset1_merged)
```

    ## # A tibble: 948 × 11
    ##   year  month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##   <fct> <fct>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ## 1 1947  Jan        23      51     253      23      45     198 dem          NA
    ## 2 1947  Feb        23      51     253      23      45     198 dem          NA
    ## 3 1947  Mar        23      51     253      23      45     198 dem          NA
    ## 4 1947  Apr        23      51     253      23      45     198 dem          NA
    ## 5 1947  May        23      51     253      23      45     198 dem          NA
    ## # ℹ 943 more rows
    ## # ℹ 1 more variable: unemployment <dbl>

## 1.5 descriptions

The first dataset`pols_month`contained information about the political
composition of government by month, including the number of Republican
and Democratic governors, senators, representatives, and the political
party of the sitting president. The data was restructured to create a
single variable indicating whether the president was Democratic or
Republican for each time period.

The second dataset`snp`contained stock market index closing values by
date. The dates were reformatted and years were converted from 2-digit
to 4-digit format (with years ≥50 treated as 1950s-1990s and years \<50
as 2000s-2040s).

The third dataset`unemployment`contained monthly unemployment
percentages by year in wide format, which was pivoted to long format
with sxeparate month and unemployment rate columns.

The final dataset`dataset1_merged`combined all three sources, using full
joins on year and month variables. It spans multiple decades and
includes key variables such as `year`, `month`, `president` (party
affiliation), numbers of Republican and Democratic officials in various
government positions (`gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`,
`sen_dem`, `rep_dem`), closing values (`close`), and unemployment rates
(`unemployment`), which provided a comprehensive view of political
composition, economic indicators, and market performance over time,
allowing for analysis of relationships between political control, stock
market performance, and unemployment rates.

# Problem 2

## 2.1 Mr. Trash Wheel sheet

``` r
Mr_Trash_wheel = 
  read_excel(
    "./trashwheel_datasets/202509 Trash Wheel Collection Data.xlsx",
    sheet = 1,
    na = c("NA", "", "."),
    skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(sports_balls_rounded = round(sports_balls))|>
  select(-sports_balls,-x15,-x16) |>
  mutate(sports_balls_rounded = as.integer(sports_balls_rounded)) |>
  mutate(year = as.double(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
print(Mr_Trash_wheel)
```

    ## # A tibble: 707 × 14
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ## # ℹ 702 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, sports_balls_rounded <int>

## 2.2 Professor Trash Wheel sheet

``` r
Prof_Trash_wheel = 
  read_excel(
    "./trashwheel_datasets/202509 Trash Wheel Collection Data.xlsx",
    sheet = 2,
    na = c("NA", "", "."),
    skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster)
print(Prof_Trash_wheel)
```

    ## # A tibble: 132 × 13
    ##   dumpster month     year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ## 2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ## 3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ## 4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ## 5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ## # ℹ 127 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

## 2.3 Gwynnda sheet

``` r
Gwynnda = 
  read_excel(
  "./trashwheel_datasets/202509 Trash Wheel Collection Data.xlsx",
  sheet = 4,
  range = cell_limits(c(2, 1), c(266, 12)),
  na = c("NA", "", "."))  |>
  janitor::clean_names() |>
  drop_na(dumpster)
print(Gwynnda)
```

    ## # A tibble: 264 × 12
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 July   2021 2021-07-03 00:00:00        0.93                 15
    ## 2        2 July   2021 2021-07-07 00:00:00        2.26                 15
    ## 3        3 July   2021 2021-07-07 00:00:00        1.62                 15
    ## 4        4 July   2021 2021-07-16 00:00:00        1.76                 15
    ## 5        5 July   2021 2021-07-30 00:00:00        1.53                 15
    ## # ℹ 259 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

## 2.4 dataset2 merged

``` r
dataset2_merged = 
  full_join(Mr_Trash_wheel, Prof_Trash_wheel, by = c("dumpster","month","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","plastic_bags","wrappers","homes_powered")) |>
  full_join(Gwynnda, by = c("dumpster","month","year","date","weight_tons","volume_cubic_yards","plastic_bottles","polystyrene","cigarette_butts","plastic_bags","wrappers","homes_powered"))
print(dataset2_merged)
```

    ## # A tibble: 1,103 × 15
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ## # ℹ 1,098 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles.x <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>, sports_balls_rounded <int>,
    ## #   glass_bottles.y <dbl>

## 2.5 descriptions

The resulting dataset contains information from all three Trash Wheel
collectors (`Mr_Trash_wheel`, `Prof_Trash_wheel`, and `Gwynnda`) with
802 observations and 15 variables. Every observation has its identical
variables
`dumpster`,`month`,`year`,`date`,`weight_tons`,`volume_cubic_yards`,`plastic_bottles`,`polystyrene`,`cigarette_butts`,`plastic_bags`,`wrappers`,`homes_powered`,meanwhile
some of the observations has the `glass_bottles`,`sports_balls`.

### 2.5.1 total weight tons (Professor Trash Wheel)

``` r
Prof_Trash_wheel |>
  drop_na(weight_tons) |>
  summarize(total_weight_tons = sum(weight_tons))
```

    ## # A tibble: 1 × 1
    ##   total_weight_tons
    ##               <dbl>
    ## 1              282.

``` r
print(Prof_Trash_wheel)
```

    ## # A tibble: 132 × 13
    ##   dumpster month     year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ## 2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ## 3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ## 4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ## 5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ## # ℹ 127 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

### 2.5.2 total cigarette butts (Gwynnda June 2022)

``` r
Gwynnda|>
  filter(year == "2022", month == "June") |>
  summarize(total_cigarette_butts = sum(cigarette_butts))
```

    ## # A tibble: 1 × 1
    ##   total_cigarette_butts
    ##                   <dbl>
    ## 1                 18120

``` r
print(Gwynnda)
```

    ## # A tibble: 264 × 12
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 July   2021 2021-07-03 00:00:00        0.93                 15
    ## 2        2 July   2021 2021-07-07 00:00:00        2.26                 15
    ## 3        3 July   2021 2021-07-07 00:00:00        1.62                 15
    ## 4        4 July   2021 2021-07-16 00:00:00        1.76                 15
    ## 5        5 July   2021 2021-07-30 00:00:00        1.53                 15
    ## # ℹ 259 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

# Problem 3

## 3.1 zip codes dataset

``` r
zip_codes = 
  read_csv(
    "./zillow_data/Zip Codes.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  separate(file_date, into = c("month","day","year"), sep = "/") |>
  select(-state_fips,-county_code) |>
  mutate(zip_code = as.character(zip_code)) |>
  arrange(zip_code, year,month,day) |>
  mutate(year = if_else(year == "07", "2007", year)) |>
  select(county,zip_code,year,month,day,everything())
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(zip_codes)
```

    ## # A tibble: 322 × 7
    ##   county   zip_code year  month day   county_fips neighborhood       
    ##   <chr>    <chr>    <chr> <chr> <chr>       <dbl> <chr>              
    ## 1 New York 10001    2007  7     25          36061 Chelsea and Clinton
    ## 2 New York 10002    2007  7     25          36061 Lower East Side    
    ## 3 New York 10003    2007  7     25          36061 Lower East Side    
    ## 4 New York 10004    2007  7     25          36061 Lower Manhattan    
    ## 5 New York 10005    2007  7     25          36061 Lower Manhattan    
    ## # ℹ 317 more rows

## 3.2 zori dataset

``` r
zori = 
  read_csv(
    "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  rename(zip_code = region_name,county = county_name) |>
  mutate(zip_code = as.character(zip_code))
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(zori)
```

    ## # A tibble: 149 × 125
    ##   region_id size_rank zip_code region_type state_name state city    metro county
    ##       <dbl>     <dbl> <chr>    <chr>       <chr>      <chr> <chr>   <chr> <chr> 
    ## 1     62080         4 11368    zip         NY         NY    New Yo… New … Queen…
    ## 2     62093         7 11385    zip         NY         NY    New Yo… New … Queen…
    ## 3     62019         9 11208    zip         NY         NY    New Yo… New … Kings…
    ## 4     62046        16 11236    zip         NY         NY    New Yo… New … Kings…
    ## 5     61807        17 10467    zip         NY         NY    New Yo… New … Bronx…
    ## # ℹ 144 more rows
    ## # ℹ 116 more variables: x2015_01_31 <dbl>, x2015_02_28 <dbl>,
    ## #   x2015_03_31 <dbl>, x2015_04_30 <dbl>, x2015_05_31 <dbl>, x2015_06_30 <dbl>,
    ## #   x2015_07_31 <dbl>, x2015_08_31 <dbl>, x2015_09_30 <dbl>, x2015_10_31 <dbl>,
    ## #   x2015_11_30 <dbl>, x2015_12_31 <dbl>, x2016_01_31 <dbl>, x2016_02_29 <dbl>,
    ## #   x2016_03_31 <dbl>, x2016_04_30 <dbl>, x2016_05_31 <dbl>, x2016_06_30 <dbl>,
    ## #   x2016_07_31 <dbl>, x2016_08_31 <dbl>, x2016_09_30 <dbl>, …

## 3.3 zori rent price dataset

``` r
zori_rent_price =
  zori |>
  mutate(county = str_remove(county, " County")) |>
  pivot_longer(
    cols = starts_with("x"),
    names_to = "date", 
    values_to = "rent_price",
    names_prefix = "x"
  ) |>
  mutate(zip_code = as.character(zip_code)) |>
  filter(!is.na(rent_price)) |>
  arrange(zip_code, date) |>
  separate(date, into = c("year","month","day"), sep = "_") |>
  select(county,zip_code,year,month,day,everything())
print(zori_rent_price)
```

    ## # A tibble: 10,450 × 13
    ##   county   zip_code year  month day   region_id size_rank region_type state_name
    ##   <chr>    <chr>    <chr> <chr> <chr>     <dbl>     <dbl> <chr>       <chr>     
    ## 1 New York 10001    2015  01    31        61615      4444 zip         NY        
    ## 2 New York 10001    2015  02    28        61615      4444 zip         NY        
    ## 3 New York 10001    2015  03    31        61615      4444 zip         NY        
    ## 4 New York 10001    2015  04    30        61615      4444 zip         NY        
    ## 5 New York 10001    2015  05    31        61615      4444 zip         NY        
    ## # ℹ 10,445 more rows
    ## # ℹ 4 more variables: state <chr>, city <chr>, metro <chr>, rent_price <dbl>

## 3.4 dataset3 merged

``` r
dataset3_merged = 
  full_join(zip_codes,zori_rent_price,by = c("zip_code","county","year","month","day"))
print(dataset3_merged)
```

    ## # A tibble: 10,772 × 15
    ##   county zip_code year  month day   county_fips neighborhood region_id size_rank
    ##   <chr>  <chr>    <chr> <chr> <chr>       <dbl> <chr>            <dbl>     <dbl>
    ## 1 New Y… 10001    2007  7     25          36061 Chelsea and…        NA        NA
    ## 2 New Y… 10002    2007  7     25          36061 Lower East …        NA        NA
    ## 3 New Y… 10003    2007  7     25          36061 Lower East …        NA        NA
    ## 4 New Y… 10004    2007  7     25          36061 Lower Manha…        NA        NA
    ## 5 New Y… 10005    2007  7     25          36061 Lower Manha…        NA        NA
    ## # ℹ 10,767 more rows
    ## # ℹ 6 more variables: region_type <chr>, state_name <chr>, state <chr>,
    ## #   city <chr>, metro <chr>, rent_price <dbl>

## 3.5 descriptions

The resulting dataset contains information from two zillow datasets
(`zip_codes`and`zori`) with 10772 observations and 15 variables. Every
observation has its identical variables
`county`,`zip_code`,`month`,`year`,`day`, and some other variables such
as`county_fips`,`neighborhood`,`region_id`,`size_rank`etc.

### 3.5.1 unique zip codes

``` r
unique_zips_merged =
  dataset3_merged |>
  distinct(zip_code) |>
  nrow()
print(unique_zips_merged)
```

    ## [1] 320

### 3.5.2 unique neighborhoods

``` r
unique_neighborhoods_merged =
  dataset3_merged |>
  drop_na(neighborhood) |>
  distinct(neighborhood) |>
  nrow()
print(unique_neighborhoods_merged)
```

    ## [1] 42

### 3.5.3 unique zip codes in `zip_codes`

``` r
zip_codes_only =
  zip_codes |>
  distinct(zip_code) |>
  anti_join(zori |> distinct(zip_code), by = "zip_code")
print(zip_codes_only)
```

    ## # A tibble: 171 × 1
    ##   zip_code
    ##   <chr>   
    ## 1 10008   
    ## 2 10020   
    ## 3 10041   
    ## 4 10043   
    ## 5 10045   
    ## # ℹ 166 more rows

### 3.5.4 possible explanation about the unique zipcodes

These ZIP codes in Manhattan, New York, are excluded from Zillow’s
database primarily because they are not typical residential areas and
lack sufficient real estate transaction data.

For example, `10008` is the location of the New York Stock Exchange, a
purely commercial and financial district with no residential properties.

Another example, `10020`, serves the Rockefeller Center, which is a
complex of offices, studios, and retail spaces, with almost no ordinary
homes available for valuation.

These areas either have no housing stock, or the properties are too
unique and rarely traded, making it impossible for Zillow’s automated
valuation model to generate a meaningful “Zestimate”.

### 3.5.5 top 10 price drops

``` r
top10_drops =
  zori_rent_price |>
  filter(year %in% c("2020","2021"), month == "01", day == "31") |> 
  select(zip_code, year, rent_price) |>
  pivot_wider(
    names_from = year, 
    values_from = rent_price,
    names_prefix = "price_of_") |>
  mutate(drop = price_of_2020 - price_of_2021) |>
  arrange(desc(drop)) |>
  drop_na(drop) |>
  head(n = 10)
print(top10_drops)
```

    ## # A tibble: 10 × 4
    ##    zip_code price_of_2020 price_of_2021  drop
    ##    <chr>            <dbl>         <dbl> <dbl>
    ##  1 10007            6334.         5422.  913.
    ##  2 10069            4623.         3875.  748.
    ##  3 10009            3406.         2692.  714.
    ##  4 10016            3731.         3019.  712.
    ##  5 10001            4108.         3398.  710.
    ##  6 10002            3645.         2935.  710.
    ##  7 10004            3150.         2444.  706.
    ##  8 10038            3573.         2876.  698.
    ##  9 10012            3629.         2942.  686.
    ## 10 10010            3697.         3012.  685.
